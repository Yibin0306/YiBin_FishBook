"""
本章所学的内容
• 参数的更新方法，除了SGD之外，还有Momentum、AdaGrad、Adam等方法。
• 权重初始值的赋值方法对进行正确的学习非常重要。
• 作为权重初始值，Xavier初始值、He初始值等比较有效。
• 通过使用Batch Normalization，可以加速学习，并且对初始值变得健壮。
• 抑制过拟合的正则化技术有权值衰减、Dropout等。
• 逐渐缩小“好值”存在的范围是搜索超参数的一个有效方法。
"""