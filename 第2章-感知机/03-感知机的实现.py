# 简单的感知机AND门实现（阈值方式）
def AND(x1, x2):
    # 权重参数
    w1, w2 = 0.5, 0.5
    # 阈值（临界值）
    theta = 0.7

    # 计算加权输入总和
    tmp = w1 * x1 + w2 * x2

    # 根据阈值判断输出
    if tmp <= theta:
        print(0)  # 加权和小于等于阈值时输出0
    elif tmp > theta:
        print(1)  # 加权和大于阈值时输出1


# 测试AND门所有输入组合
AND(0, 0)  # 应输出0
AND(0, 1)  # 应输出0
AND(1, 0)  # 应输出0
AND(1, 1)  # 应输出1

# ================= 使用权重和偏置的实现 =================
"""
引入偏置(bias)的概念：
原公式：w1*x1 + w2*x2 > θ  → 激活
转换为：w1*x1 + w2*x2 + b > 0  → 激活
其中 b = -θ
"""
import numpy as np

# 演示偏置和权重的计算
x = np.array([0, 1])  # 输入向量
w = np.array([0.5, 0.5])  # 权重向量
b = -0.7  # 偏置值（对应阈值θ=0.7）

print(w * x)  # 计算权重与输入的乘积：[0.0, 0.5]
print(np.sum(w * x))  # 计算加权和：0.5
print(np.sum(w * x) + b)  # 加入偏置：0.5 + (-0.7) = -0.2


# 使用权重和偏置改进的AND门实现
def AND(x1, x2):
    x = np.array([x1, x2])  # 输入向量
    w = np.array([0.5, 0.5])  # 权重向量
    b = -0.7  # 偏置值

    # 计算加权输入总和 + 偏置
    tmp = np.sum(w * x) + b

    # 根据激活函数判断输出
    if tmp <= 0:
        print(0)  # 总和≤0时输出0
    elif tmp > 0:
        print(1)  # 总和>0时输出1


"""
偏置的作用：
1. 决定神经元被激活的容易程度
2. 偏置值越小，神经元越容易被激活
3. 有时统称权重和偏置为"参数"
"""


# ================= 实现其他逻辑门 =================

# 与非门(NAND)实现
def NAND(x1, x2):
    x = np.array([x1, x2])
    # 权重取负值，偏置取正值（与AND门相反）
    w = np.array([-0.5, -0.5])
    b = 0.7  # 正偏置

    tmp = np.sum(w * x) + b
    if tmp <= 0:
        print(0)
    else:
        print(1)  # 仅当两个输入均为1时输出0


# 或门(OR)实现
def OR(x1, x2):
    x = np.array([x1, x2])
    # 权重与AND相同，但使用更小的偏置（绝对值）
    w = np.array([0.5, 0.5])
    b = -0.2  # 较小的负偏置，降低激活阈值

    tmp = np.sum(w * x) + b
    if tmp <= 0:
        print(0)
    else:
        print(1)  # 任一输入为1即输出1