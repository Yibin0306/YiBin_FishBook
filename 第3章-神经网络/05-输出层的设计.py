"""
神经网络输出层激活函数的选择：
- 回归问题：恒等函数（直接输出原始值）
- 分类问题：softmax函数（输出概率分布）
分类问题：判断数据所属类别（如识别图像中人像的性别）
回归问题：预测连续数值（如根据人像预测体重）
"""

import numpy as np

"""
激活函数说明：
恒等函数：原样输出输入值，不做任何变换
softmax函数：将输入转换为概率分布，输出总和为1
数学表达式：softmax(z_i) = e^{z_i} / sum_{j=1}^{K} e^{z_j}
"""

# === softmax函数实现示例 ===

# 示例输入向量
a = np.array([0.3, 2.9, 4.0])
# 计算每个元素的指数值
exp_a = np.exp(a)
print(exp_a)  # [1.34985881, 18.17414537, 54.59815003]
# 计算所有指数值的总和
sum_exp_a = np.sum(exp_a)
print(sum_exp_a)  # 74.1221542101633
# 将每个指数值除以总和，得到概率分布
y = exp_a / sum_exp_a
print(y)  # [0.01821127, 0.24519181, 0.73659691]

# === 基础softmax函数实现 ===
def softmax(a):
    """基础softmax函数实现（存在数值溢出风险）"""
    exp_a = np.exp(a)  # 计算指数
    sum_exp_a = np.sum(exp_a)  # 计算指数和
    y =  exp_a / sum_exp_a  # 归一化为概率分布
    return y

# === 数值稳定性问题及解决方案 ===
"""
计算机数值表示限制：
- 数值有有限的范围（4/8字节宽度）
- 超大值无法表示（称为溢出问题）
- 指数函数快速增长，容易导致溢出
"""

# 数值溢出示例
a = np.array([1010, 1000, 990]) # 直接计算会出现溢出问题
# 解决方案：减去最大值（保持数学等价性）
c = np.max(a)  # 找到输入向量中的最大值
print(a - c)  # 所有元素减去最大值 [0, -10, -20]
print(softmax(a - c))  # 安全计算概率分布 [9.99954600e-01, 4.53978686e-05, 2.06106005e-09]

# === 优化后的softmax函数实现 ===
def softmax(a):
    """数值稳定的softmax函数实现"""
    c = np.max(a)  # 获取输入向量中的最大值
    exp_a = np.exp(a - c)  # 减去最大值再计算指数（防止溢出）
    sum_exp_a = np.sum(exp_a)  # 计算指数和
    y = exp_a / sum_exp_a  # 归一化为概率分布
    return y

# === softmax函数特性验证 ===
a = np.array([0.3, 2.9, 4.0])
y = softmax(a)
print(y)  # 输出概率分布 [0.01821127, 0.24519181, 0.73659691]
print(np.sum(y))  # 验证概率和为1.0
"""
softmax函数特性：
1. 输出值在0.0到1.0之间
2. 输出总和恒等于1
3. 输出可解释为概率
4. 适合用于分类问题的输出层
"""